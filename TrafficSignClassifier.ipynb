{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Sign Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = 'train.p'\n",
    "validation_file= 'valid.p'\n",
    "testing_file =  'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print('Data Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of testing examples = 12630\n",
      "Number of testing samples = 12630\n",
      "Image data shape = (32, 32)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "n_validation = X_valid.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "image_shape = X_train.shape[1:3]\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Number of testing samples =\",n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Random Images From Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDINdsDAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f7f390390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "#Plot images from the features set\n",
    "image_num = random.randint(0,n_train)\n",
    "image = X_train[image_num]\n",
    "if(len(image.shape) > 2):\n",
    "    imgplot = plt.imshow(image)\n",
    "else:\n",
    "    imgplot = plt.imshow(image,cmap='gray')\n",
    "\"\"\"\n",
    "    \n",
    "plt.hist(y_train,43)\n",
    "plt.hist(y_valid,43)\n",
    "plt.hist(y_test,43)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images converted to grayscale\n"
     ]
    }
   ],
   "source": [
    "def rgb2gray(images):\n",
    "    \n",
    "    r, g, b = images[:,:,:,0], images[:,:,:,1], images[:,:,:,2]\n",
    "    gray = 0.2126 * r + 0.7152* g + 0.0722 * b\n",
    "    return gray\n",
    "\n",
    "#Convert to grayscale and reshape\n",
    "if(len(X_train.shape) > 3):\n",
    "    X_train = np.reshape(rgb2gray(X_train),(n_train,32,32,1))\n",
    "    X_valid = np.reshape(rgb2gray(X_valid),(n_validation,32,32,1))\n",
    "    X_test = np.reshape(rgb2gray(X_test),(n_test,32,32,1))\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Images converted to grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example architecture\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x,keep_prob):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.01\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x10.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 10), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(10))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # Pooling. Input = 28x28x10. Output = 14x14x10.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    #Dropout\n",
    "    conv1 = tf.nn.dropout(conv1,keep_prob)\n",
    "    \n",
    "    # Layer 2: Convolutional Input = 14x14x10 Output = 10x10x24.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 10, 24), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(24))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # Pooling. Input = 10x10x24. Output = 5x5x24.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #Dropout\n",
    "    conv2 = tf.nn.dropout(conv2,keep_prob)\n",
    "    \n",
    "    # Flatten. Input = 5x5x16. Output = 600.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 600. Output = 240.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(600, 240), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(240))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 240. Output = 120.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(240, 120), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(120))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 120. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(120, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Built\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Training Parameters\n",
    "learning_rate = 0.0002\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "KEEP_PROB = 0.65\n",
    "\n",
    "#Model\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32,shape=(None,32,32,1))\n",
    "logits=LeNet(x,keep_prob)\n",
    "\n",
    "y = tf.placeholder(tf.int32,(None))\n",
    "one_hot_y = tf.one_hot(y,43)\n",
    "\n",
    "\n",
    "# Calculate the loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "#Set up the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "print(\"Model Built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "prediction = tf.argmax(logits,1)\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "softmax_logits = tf.nn.softmax(logits)\n",
    "top_k = tf.nn.top_k(softmax_logits,k=5)\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y,keep_prob: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.239\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.587\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.719\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.789\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.812\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.851\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.866\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.875\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.898\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.916\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.919\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.912\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.926\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.928\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.934\n",
      "\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.948\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.936\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 41 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 42 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 43 ...\n",
      "Validation Accuracy = 0.946\n",
      "\n",
      "EPOCH 44 ...\n",
      "Validation Accuracy = 0.948\n",
      "\n",
      "EPOCH 45 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 46 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 47 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "EPOCH 48 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 49 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 50 ...\n",
      "Validation Accuracy = 0.951\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Initiate variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_op, feed_dict={x: batch_x, y: batch_y,keep_prob:KEEP_PROB})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.933\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test Model on Images from the Internet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Output the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "(1, 32, 32, 3)\n",
      "(1, 32, 32, 3)\n",
      "(1, 32, 32, 3)\n",
      "(1, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f7f320cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "size = [32,32]\n",
    "images = []\n",
    "y_internet = np.array([23,14,1,13,25])\n",
    "\n",
    "for i in range(1,6):\n",
    "    img_loc = 'germansigns/sign' + str(i) + '.jpg'\n",
    "    img = Image.open(img_loc)\n",
    "    img = img.resize(size,Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "    img = np.resize(img,(1,32,32,3))\n",
    "    \n",
    "    images.append(img)\n",
    "    print(img.shape)\n",
    "\n",
    "X_internet = np.vstack(images)\n",
    "\n",
    "#Plot image\n",
    "image = X_internet[4]\n",
    "imgplot = plt.imshow(image)\n",
    "\n",
    "#Convert to grayscale\n",
    "#X_internet = np.resize(rgb2gray(X_internet),(X_internet.shape[0],32,32,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Sign Type for Each Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Prediction is [23 14 36 13 10]\n",
      "Accuracy is 0.600000023842\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "    \n",
    "    prediction = sess.run(prediction, feed_dict={x: X_internet, y: y_internet,keep_prob: 1.0})\n",
    "    print(\"Prediction is \" + str(prediction))\n",
    "    \n",
    "    validation_accuracy = evaluate(X_internet, y_internet)\n",
    "    print(\"Accuracy is \" + str(validation_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Top 5 Softmax Probabilities For Each Image Found on the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Top Softmax are: \n",
      "[[ 1.       0.       0.       0.       0.     ]\n",
      " [ 0.99995  0.00004  0.00001  0.       0.     ]\n",
      " [ 0.75724  0.17651  0.02278  0.02167  0.02018]\n",
      " [ 1.       0.       0.       0.       0.     ]\n",
      " [ 0.90352  0.09557  0.00089  0.00002  0.     ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './lenet')\n",
    "    softmax = sess.run(top_k,feed_dict={x: X_internet, y: y_internet,keep_prob: 1.0})\n",
    "    print(\"Top Softmax are: \")\n",
    "    np.set_printoptions(precision=5,suppress=True)\n",
    "    print(softmax[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Writeup\n",
    "\n",
    "Once you have completed the code implementation, document your results in a project writeup using this [template](https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project/blob/master/writeup_template.md) as a guide. The writeup can be in a markdown or pdf file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
